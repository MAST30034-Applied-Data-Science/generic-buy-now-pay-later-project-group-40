{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import geopandas as gpd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 19:04:12 WARN Utils: Your hostname, DESKTOP-3NQ3PQI resolves to a loopback address: 127.0.1.1; using 172.31.182.220 instead (on interface eth0)\n",
      "22/09/26 19:04:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 19:04:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/09/26 19:04:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/09/26 19:04:15 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 2 Preprocessing\")\n",
    "    .config(\"spark.driver.memory\", '4g')\n",
    "    .config(\"spark.executor.memory\", '8g')\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.sql.parquet.enableVectorizedReader\",\"false\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.parquet.writeLegacyFormat\", 'true')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Postcode to ABS Postal Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postcode_to_str(col):\n",
    "    return col.astype(str).str.zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "postal_areas_gdf = gpd.read_file('../data/raw/postcodes/abs_postal_areas.zip')\n",
    "consumer_details_df = pd.read_parquet('../data/curated/cleaned_consumers.parquet')\n",
    "postcode_df = pd.read_csv('../data/raw/postcodes/postcodes.csv').drop_duplicates('postcode')\n",
    "\n",
    "consumer_details_df['postcode'] = postcode_to_str(consumer_details_df['postcode'])\n",
    "postcode_df['postcode'] = postcode_to_str(postcode_df['postcode'])\n",
    "\n",
    "# Convert postcode dataframe to geodataframe\n",
    "postcode_gdf = gpd.GeoDataFrame(\n",
    "    postcode_df, geometry=gpd.points_from_xy(postcode_df['long'], postcode_df['lat'])\n",
    ")\n",
    "postcode_gdf.crs = postal_areas_gdf.crs\n",
    "\n",
    "# Get list of postcodes not listed as abs postal areas and filter geodataframe to just these postcodes\n",
    "unmapped = consumer_details_df[~consumer_details_df['postcode'].astype(str).str.zfill(4).isin(postal_areas_gdf['POA_CODE21'])]['postcode'].unique()\n",
    "postcodes_gdf = postcode_gdf[postcode_gdf['postcode'].isin(unmapped)]\n",
    "\n",
    "# Spatially join unmapped postcodes and abs postal areas\n",
    "postcode_poa_gdf = postcodes_gdf.sjoin(postal_areas_gdf, how = 'inner')\n",
    "\n",
    "# Remove and rename columns \n",
    "postcode_poa_df = postcode_poa_gdf[['postcode', 'POA_CODE21']]\n",
    "postcode_poa_df = postcode_poa_df.rename(columns = {'POA_CODE21' : 'poa'})\n",
    "\n",
    "# Combine abs mapped postcodes with unmapped postcodes\n",
    "postcode_poa_df = pd.concat([postcode_poa_df, postal_areas_gdf[['POA_CODE21', 'POA_CODE21']].set_axis(['postcode', 'poa'], axis = 1)], ignore_index = True).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../data/curated/census/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "postcode_poa_df.to_parquet(output_dir + 'postcode_poa.parquet', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All but 2 postcodes could be mapped to abs postal areas. Niether of these could be found in the Australia post website. https://postcodes-australia.com/postcodes/6958 says 6958 is a Western Australian postcode reserved for non standard use<br><br>\n",
    "This results in the removal of 317 consumers from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_consumers = consumer_details_df[~consumer_details_df['postcode'].astype(str).str.zfill(4).isin(postcode_poa_df['postcode'])]\n",
    "len(removed_consumers), removed_consumers['postcode'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age/Gender Weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "age_df = pd.read_parquet(\n",
    "    '../data/curated/census/age_data.parquet'\n",
    ")\n",
    "\n",
    "postcode_poa_df = pd.read_parquet(\n",
    "    '../data/curated/census/postcode_poa.parquet'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate population by age intervals (18-24, 25-34, 35-44, 45-54, 55-64, 65+) at POA and national level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for start_yr, end_yr in zip([18,25,35,45,55], [25,35,45,55,65]):\n",
    "    for g in ['m', 'f', 'p']:\n",
    "        col = f'age_{start_yr}_{end_yr - 1}_{g}'\n",
    "        cols.append(col)\n",
    "        age_df[col] = age_df.filter(regex = '|'.join([f'(age_yr_{x}_{g})'for x in range(start_yr,end_yr)])).astype(int).sum(axis = 1)\n",
    "\n",
    "for g in ['m', 'f', 'p']:\n",
    "    col = f'age_65+_{g}'\n",
    "    cols.append(col)\n",
    "    age_df[col] = age_df.filter(regex = '|'.join([f'(age_yr_{x}_{x+4}_{g})'for x in range(65,100, 5)] + ['age_yr_100_yr_over_[mf]'])).astype(int).sum(axis = 1)\n",
    "\n",
    "\n",
    "age_df = age_df[['poa'] + cols].melt(id_vars = 'poa')\n",
    "\n",
    "def get_gender(variable):\n",
    "    g = variable[-1]\n",
    "    if g == 'm':\n",
    "        return 'Male'\n",
    "    if g == 'f':\n",
    "        return 'Female'\n",
    "    if g == 'p':\n",
    "        return 'Person'\n",
    "\n",
    "age_df['gender'] = age_df['variable'].apply(get_gender)\n",
    "age_df['variable'] = age_df['variable'].apply(lambda x : x[:-2])\n",
    "age_df = pd.pivot_table(age_df, values = 'value', index =['poa', 'gender'], columns='variable')\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "aus_age = age_df.loc[idx[:, 'Person'], :].sum()\n",
    "aus_age_m = age_df.loc[idx[:, 'Male'], :].sum()\n",
    "aus_age_f = age_df.loc[idx[:, 'Female'], :].sum()\n",
    "\n",
    "aus_prob_m = aus_age_m.sum()/(aus_age.sum())\n",
    "\n",
    "aus_age *= 1/aus_age.sum()\n",
    "aus_age_m *= 1/aus_age_m.sum()\n",
    "aus_age_f *= 1/aus_age_f.sum()\n",
    "\n",
    "age_df = age_df.apply(lambda x : x/x.sum(), axis = 1)\n",
    "age_df = age_df.fillna(age_df.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caculates weights for each combination of gender and postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for probability calculations\n",
    "prob_bnpl = 0.05\n",
    "prob_female_g_bnpl = 0.57\n",
    "prob_male_g_bnpl = 0.43\n",
    "\n",
    "prob_age_g_bnpl = pd.Series(data = {'age_18_24' : 0.26, 'age_25_34' : 0.35, 'age_35_44' : 0.2, 'age_45_54' : 0.12, 'age_55_64' : 0.04,'age_65+' : 0.01})\n",
    "\n",
    "prob_bnpl_g_age_m = prob_age_g_bnpl*prob_male_g_bnpl*prob_bnpl/aus_age_m/aus_prob_m\n",
    "prob_bnpl_g_age_f = prob_age_g_bnpl*prob_female_g_bnpl*prob_bnpl/aus_age_f/(1-aus_prob_m)\n",
    "prob_bnpl_g_age = prob_age_g_bnpl*prob_bnpl/aus_age\n",
    "\n",
    "def get_prob_bnpl(row):\n",
    "    if row.name[1] == 'Male':\n",
    "        return (row*prob_bnpl_g_age_m).sum()\n",
    "    if row.name[1] == 'Female':\n",
    "        return (row*prob_bnpl_g_age_f).sum()\n",
    "    if row.name[1] == 'Person':\n",
    "        return (row*prob_bnpl_g_age).sum()\n",
    "\n",
    "age_df['weight'] = age_df.apply(get_prob_bnpl, axis = 1)\n",
    "age_df = age_df[['weight']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform index and write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_df = age_df.reset_index()\n",
    "age_df['gender'] = age_df['gender'].apply(lambda x : 'Undisclosed' if x == 'Person' else x)\n",
    "\n",
    "age_df.to_parquet('../data/curated/demographic_weights.parquet', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
