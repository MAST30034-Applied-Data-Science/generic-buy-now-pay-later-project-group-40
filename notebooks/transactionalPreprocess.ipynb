{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/19 12:31:59 WARN Utils: Your hostname, dash_surface resolves to a loopback address: 127.0.1.1; using 172.31.0.166 instead (on interface eth0)\n",
      "22/09/19 12:31:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/19 12:32:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 2\")\n",
    "    .config(\"spark.driver.memory\", '4g')\n",
    "    .config(\"spark.executor.memory\", '8g')\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.sql.parquet.enableVectorizedReader\",\"false\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load consumer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------------+-----+--------+-----------+-----------+\n",
      "|name              |address                     |state|postcode|gender     |consumer_id|\n",
      "+------------------+----------------------------+-----+--------+-----------+-----------+\n",
      "|Jonathan Compton  |0815 Alicia Centers         |NSW  |2594    |Male       |650538     |\n",
      "|Alice Roberts     |76407 Audrey Falls Apt. 548 |NSW  |1630    |Female     |1401331    |\n",
      "|Michael Leach DVM |16427 Webster Orchard       |NSW  |1108    |Male       |3341       |\n",
      "|Michelle Rodriguez|805 Justin Landing Suite 305|NSW  |2506    |Undisclosed|624863     |\n",
      "|Tara Harris       |0528 Andrea Ferry           |NSW  |2442    |Female     |193993     |\n",
      "+------------------+----------------------------+-----+--------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Run consumerPreprocessing.ipynb to get data\n",
    "\n",
    "sdf_consumer = spark.read.parquet('../data/curated/cleaned_consumers')\n",
    "sdf_consumer.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "498933"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_consumer.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load transactional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Reading in all transaction data and joining them\n",
    "sdf_transactions1 = spark.read.parquet('../data/tables/transactions_20210228_20210827_snapshot')\n",
    "sdf_transactions2 = spark.read.parquet('../data/tables/transactions_20210828_20220227_snapshot')\n",
    "sdf_transactions3 = spark.read.parquet('../data/tables/transactions_20220228_20220828_snapshot')\n",
    "\n",
    "sdf_transactions = sdf_transactions1.union(sdf_transactions2)\n",
    "sdf_transactions = sdf_transactions.union(sdf_transactions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14195505"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_transactions.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read consumer details (joining table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_userdetails = spark.read.parquet('../data/tables/consumer_user_details.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join transactional data with consumer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_usertransaction = sdf_userdetails.join(sdf_transactions, on='user_id')\n",
    "sdf_consumer_transaction = sdf_usertransaction.join(sdf_consumer, on='consumer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keeping useful features\n",
    "sdf_consumer_transaction = sdf_consumer_transaction.select(\"consumer_id\",\"user_id\",'merchant_abn','dollar_value',\n",
    "                            'order_datetime','state','postcode','gender')               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>gender</th><th>count</th></tr>\n",
       "<tr><td>Undisclosed</td><td>1440093</td></tr>\n",
       "<tr><td>Female</td><td>6296649</td></tr>\n",
       "<tr><td>Male</td><td>6433949</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+-------+\n",
       "|     gender|  count|\n",
       "+-----------+-------+\n",
       "|Undisclosed|1440093|\n",
       "|     Female|6296649|\n",
       "|       Male|6433949|\n",
       "+-----------+-------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking gender categories\n",
    "sdf_consumer_transaction.groupBy('gender').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our genders, it may be a promising feature which woucl dbe used further along the line. Thus, we want to keep it for future references. However, there are people who wish to not disclose their gender and a gender feature as 'undisclosed' has appeared. The following code deals with attempting to find if there has been any past that customers who have said 'undisclosed' have provided us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first set of data, doesn't seem like there's any overlap. Smoge useless analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round dollar values to 2dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round to 2 decimal places, and define a transaction range\n",
    "min_value = 0\n",
    "max_value = 10000\n",
    "sdf_consumer_transaction = sdf_consumer_transaction.withColumn('dollar_value', F.round(F.col('dollar_value'), 2))\n",
    "sdf_consumer_transaction = sdf_consumer_transaction.where(\n",
    "    (F.col('dollar_value') > min_value)\n",
    "    & (F.col('dollar_value') <= max_value)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check ABN validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure ABN is valid, takes in long\n",
    "\n",
    "def validateABN(merchant_abn):\n",
    "\n",
    "    str_abn = str(merchant_abn)\n",
    "\n",
    "    if len(str_abn) == 11:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a list of all row values, used for validating ABN\n",
    "\n",
    "sdf_list = sdf_consumer_transaction.select(\"merchant_abn\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find any merchants without a valid ABN\n",
    "\n",
    "i = 0\n",
    "invalidABN = []\n",
    "\n",
    "while i < len(sdf_list):\n",
    "    abn = str(sdf_list[i].__getitem__('merchant_abn'))\n",
    "    if validateABN(abn) == False:\n",
    "        invalidABN.append(abn)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalidABN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ez no invalid abn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12534085"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking date range\n",
    "start_date = '2021-02-28'\n",
    "end_date = '2022-08-28'\n",
    "sdf_consumer_transaction = sdf_consumer_transaction.where(\n",
    "    (F.col('order_datetime') >= start_date) & (F.col('order_datetime') <= end_date)\n",
    ")\n",
    "sdf_consumer_transaction.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Export cleaned data\n",
    "\n",
    "sdf_consumer_transaction.write.parquet(\"../data/curated/cleaned_transactions.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
