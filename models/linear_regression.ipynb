{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import geopandas as gpd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 2 Preprocessing\")\n",
    "    .config(\"spark.driver.memory\", '4g')\n",
    "    .config(\"spark.executor.memory\", '8g')\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.sql.parquet.enableVectorizedReader\",\"false\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.parquet.writeLegacyFormat\", 'true')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model(df,indexCols,categoricalCols,continuousCols, interactionCols, labelCol):\n",
    "    \"\"\"\n",
    "    Creates a linear regression model for the specified input column types, interaction columns and label column\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    indexers = [ StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c), handleInvalid = \"skip\")\n",
    "                 for c in categoricalCols ]\n",
    "\n",
    "    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),\n",
    "                 outputCol=\"{0}_encoded\".format(indexer.getOutputCol()))\n",
    "                 for indexer in indexers ]\n",
    "    \n",
    "    interactions = [\n",
    "        Interaction(\n",
    "            inputCols = [\n",
    "            f'{col}_indexed_encoded'\n",
    "            for col in interactionCol\n",
    "        ],\n",
    "            outputCol = '_'.join(interactionCol)\n",
    "        ) \n",
    "        for interactionCol in interactionCols\n",
    "    ]\n",
    "\n",
    "    interactions += [\n",
    "        Interaction(\n",
    "            inputCols = ['LocationID_indexed_encoded', 'months_lapsed'],\n",
    "            outputCol = 'LocID_months_lapsed'\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    interactions +=[\n",
    "        Interaction(\n",
    "            inputCols = ['hour_indexed_encoded', feature],\n",
    "            outputCol = f'{feature}_hour'\n",
    "        )\n",
    "        for feature in ['prec', 'snowfall', 'skin_temp']\n",
    "    ]\n",
    "    \n",
    "    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]\n",
    "                                + [interaction.getOutputCol() for interaction in interactions]\n",
    "                                + continuousCols, outputCol=\"features\")\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        stages=\n",
    "        indexers \n",
    "        + encoders \n",
    "        + interactions \n",
    "        + [assembler]\n",
    "    )\n",
    "\n",
    "    model=pipeline.fit(df)\n",
    "    data = model.transform(df)\n",
    "\n",
    "    data = data.withColumn('label',F.col(labelCol))\n",
    "\n",
    "    tf_sdf = data.select(indexCols +['features','label'])\n",
    "\n",
    "    featureIndexer = VectorIndexer(inputCol=\"features\", \\\n",
    "                               outputCol=\"indexedFeatures\").fit(tf_sdf)\n",
    "\n",
    "    tf_sdf = featureIndexer.transform(tf_sdf)\n",
    "\n",
    "    training_sdf = tf_sdf.where(\n",
    "        F.col('datetime') < '2019-06-01'\n",
    "    )\n",
    "\n",
    "    testing_sdf = tf_sdf.where(\n",
    "        F.col('datetime') >= '2019-06-01'\n",
    "    )\n",
    "\n",
    "    lr = LinearRegression(regParam=0.3)\n",
    "\n",
    "    pipeline = Pipeline(stages=[featureIndexer, lr])\n",
    "    \n",
    "    return pipeline.fit(training_sdf).transform(testing_sdf)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
