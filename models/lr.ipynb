{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, Interaction\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor, FMRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/09 22:03:01 WARN Utils: Your hostname, DESKTOP-3NQ3PQI resolves to a loopback address: 127.0.1.1; using 172.17.27.14 instead (on interface eth0)\n",
      "22/10/09 22:03:01 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/09 22:03:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 2\")\n",
    "    .config(\"spark.driver.memory\", '8g')\n",
    "    .config(\"spark.executor.memory\", '8g')\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.sql.parquet.enableVectorizedReader\",\"false\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_sdf  = spark.read.parquet('../data/curated/weighted_transactions.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_parquet('../data/curated/weighted_transactions.parquet')\n",
    "merchant_df = pd.read_parquet('../data/curated/merchants.parquet')\n",
    "segments_df = pd.read_csv('../data/curated/segments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     ['antique shops - sales', 'repairs', 'restorat...\n",
       "1                          ['art dealers', 'galleries']\n",
       "2                      ['artist supply', 'craft shops']\n",
       "3                  ['bicycle shops - sales', 'service']\n",
       "4                ['books', 'periodicals', 'newspapers']\n",
       "5     ['cable', 'satellite', 'other pay television',...\n",
       "6     ['computer programming', 'data processing', 'i...\n",
       "7     ['computers', 'computer peripheral equipment',...\n",
       "8           ['digital goods: books', 'movies', 'music']\n",
       "9     ['equipment', 'tool', 'furniture', 'appliance ...\n",
       "10    ['florists supplies', 'nursery stock', 'flowers']\n",
       "11    ['furniture', 'home furnishings', 'equipment s...\n",
       "12        ['gift', 'card', 'novelty', 'souvenir shops']\n",
       "13                            ['health', 'beauty spas']\n",
       "14                       ['hobby', 'toy', 'game shops']\n",
       "15    ['jewelry', 'watch', 'clock', 'silverware shops']\n",
       "16    ['lawn', 'garden supply outlets', 'including n...\n",
       "17              ['motor vehicle supplies', 'new parts']\n",
       "18    ['music shops - musical instruments', 'pianos'...\n",
       "19         ['opticians', 'optical goods', 'eyeglasses']\n",
       "20                                       ['shoe shops']\n",
       "21    ['stationery', 'office supplies', 'printing', ...\n",
       "22                                          ['telecom']\n",
       "23                             ['tent', 'awning shops']\n",
       "24           ['watch', 'clock', 'jewelry repair shops']\n",
       "Name: category, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_sdf.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model(df,indexCols,categoricalCols,continuousCols, interactionCols, labelCol):\n",
    "    \"\"\"\n",
    "    Creates a linear regression model for the specified input column types, interaction columns and label column\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    indexers = [ StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c), handleInvalid = \"skip\")\n",
    "                 for c in categoricalCols ]\n",
    "\n",
    "    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),\n",
    "                 outputCol=\"{0}_encoded\".format(indexer.getOutputCol()))\n",
    "                 for indexer in indexers ]\n",
    "    \n",
    "    interactions = [\n",
    "        Interaction(\n",
    "            inputCols = [\n",
    "            f'{col}_indexed_encoded'\n",
    "            for col in interactionCol\n",
    "        ],\n",
    "            outputCol = '_'.join(interactionCol)\n",
    "        ) \n",
    "        for interactionCol in interactionCols\n",
    "    ]\n",
    "    \n",
    "    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]\n",
    "                                + [interaction.getOutputCol() for interaction in interactions]\n",
    "                                + continuousCols, outputCol=\"features\")\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        stages=\n",
    "        indexers \n",
    "        + encoders \n",
    "        + interactions \n",
    "        + [assembler]\n",
    "    )\n",
    "\n",
    "    model=pipeline.fit(df)\n",
    "    data = model.transform(df)\n",
    "\n",
    "    data = data.withColumn('label',F.col(labelCol))\n",
    "\n",
    "    tf_sdf = data.select(indexCols +['features','label'])\n",
    "\n",
    "    featureIndexer = VectorIndexer(inputCol=\"features\", \\\n",
    "                               outputCol=\"indexedFeatures\").fit(tf_sdf)\n",
    "\n",
    "    tf_sdf = featureIndexer.transform(tf_sdf)\n",
    "\n",
    "    training_sdf = tf_sdf.where(\n",
    "        F.col('datetime') < '2019-06-01'\n",
    "    )\n",
    "\n",
    "    testing_sdf = tf_sdf.where(\n",
    "        F.col('datetime') >= '2019-06-01'\n",
    "    )\n",
    "\n",
    "    lr = LinearRegression(regParam=0.3)\n",
    "\n",
    "    pipeline = Pipeline(stages=[featureIndexer, lr])\n",
    "    \n",
    "    return pipeline.fit(training_sdf).transform(testing_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regression_model(transactions_sdf, ['merchant_abn', 'week_idx'], ['merchant_abn', 'week_of_year'], [], [['merchant_abn', 'week_of_year']], 'weighted_dollar_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92ea58c70db46728db75825e7170aaba7ae15ca2d0e36751b515e78ab3619849"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('ads_proj2': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
